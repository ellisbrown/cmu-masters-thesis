\chapter{Conclusions and Future Directions}
\label{sec:conclusions}


% In conclusion, our proposed Internet Explorer system demonstrates the vast potential of utilizing the Internet as an interactive and dynamic source of highly relevant training data for improving performance in visual tasks. By employing self-supervised learning techniques and adaptively searching for images through Google Image Search, Internet Explorer can efficiently match or even surpass the performance of compute-intensive oracle models such as CLIP, which rely on static datasets. Furthermore, our approach outperforms strong baselines that search the Internet in an undirected manner, showcasing the effectiveness of the nearest-neighbors curiosity reward and text similarity in optimizing the training process.

% There are several promising directions for future research in this area. Scaling Internet Explorer to larger and more diverse datasets, such as ImageNet, could further enhance its capabilities and applicability. Additionally, exploring more challenging vision tasks, videos, and robotics would provide valuable insights into the system's adaptability and efficacy. Investigating alternative metrics for quantifying the usefulness of images, as well as integrating other self-supervised learning algorithms like Masked Autoencoder, could lead to improvements in handling degenerate Internet images. Finally, the possibility of fine-tuning a CLIP model online using captions and search terms offers another avenue for leveraging the dynamic nature of the open web in the quest for more efficient and effective machine learning models.


% Our proposed Internet Explorer system demonstrates the vast potential of utilizing the Internet as an interactive and dynamic source of highly relevant training data for improving performance in visual tasks. By employing self-supervised learning techniques and adaptively searching for images through Google Image Search, Internet Explorer can efficiently match or even surpass the performance of compute-intensive oracle models such as CLIP, which rely on static datasets. Furthermore, our approach outperforms strong baselines that search the Internet in an undirected manner, showcasing the effectiveness of the nearest-neighbors curiosity reward and text similarity in optimizing the training process.

% In this work, we propose Internet Explorer, an unsupervised system that autonomously learns to collect image data from the Internet in order to improve performance on a target visual task. Internet Explorer performs self-supervised learning on relevant images it adaptively finds with Google Image Search. This enables it to match or surpass the performance of models trained for much longer on much more data. 
% This relies on a nearest-neighbors curiosity reward that encourages new images to be close to the target dataset images in representation space. Internet Explorer also uses text similarity to predict how unseen queries will perform. We show that this is an efficient training method that can approach or even surpass the performance of models trained for much longer and on much more data. 
% There are quite a few avenues for future work. 
% While the nearest neighbors reward works well empirically, there likely exists better metrics that quantify how useful a particular image is. Other types of self-supervised learning algorithms, such as Masked Autoencoder~\cite{he2022masked}, may be a better fit for degenerate Internet images. Finally, Internet videos could be a richer source of data to explore. \\

% We show that interactively exploring the Internet is an efficient source of highly relevant training data---if one knows how to search for it. In just 30--40 hours of training on a single GPU, Internet Explorer either significantly outperforms or closely matches the performance of compute-heavy \textit{oracle} models like CLIP~\cite{radford2021learning} trained on static datasets, as well as strong baselines that search the Internet in an undirected manner.



% In conclusion, we have demonstrated the potential of Internet Explorer, an unsupervised system that autonomously gathers image data from the Internet to enhance performance on target visual tasks. By employing self-supervised learning on relevant images adaptively discovered through Google Image Search, Internet Explorer can match or even surpass the performance of models trained on considerably larger datasets and for longer durations. Our approach leverages a nearest-neighbors curiosity reward, which encourages the selection of new images closely related to the target dataset images in representation space. Moreover, Internet Explorer utilizes text similarity to predict the performance of unseen queries efficiently.

% Our findings indicate that interactively exploring the Internet is an effective source of highly relevant training data when equipped with the right search strategies. Internet Explorer achieves remarkable results in just 30-40 hours of training on a single GPU, either significantly outperforming or closely matching the performance of compute-heavy oracle models like CLIP, trained on static datasets, as well as strong baselines that search the Internet in an undirected manner.

% There are several promising avenues for future work. Although the nearest neighbors reward has proven successful empirically, it is likely that more sophisticated metrics could be employed to better quantify the usefulness of a particular image. Furthermore, alternative self-supervised learning algorithms, such as the Masked Autoencoder, may offer a better fit for degenerate Internet images. Another exciting direction for exploration is the incorporation of Internet videos, which could provide a richer source of data. As we scale to larger and more diverse datasets like ImageNet, our approach could be applied to more challenging visual tasks, videos, and robotics. Finally, the possibility of fine-tuning a CLIP model online using captions and search terms could pave the way for even more effective and adaptive models.

We propose a novel paradigm for training machine learning models that leverages the Internet as a dynamic and interactive source of highly relevant training data. Instead of relying on fine-tuning general-purpose models pre-trained on large, static datasets, we propose a method that focuses on training a small-scale model that excels on specific tasks at hand. Our system, Internet Explorer, explores the Web in a self-supervised manner, learning to collect images via text-to-image search engines that are relevant to and improve performance on the task at hand.
% We show that Internet Explorer can match or even surpass the performance of compute-intensive oracle models such as CLIP, which rely on static datasets. Furthermore, our approach outperforms strong baselines that search the Internet in an undirected manner, showcasing the effectiveness of the nearest-neighbors curiosity reward and text similarity in optimizing the training process.

Our findings indicate that interactively exploring the Internet is an effective source of highly relevant training data when equipped with the right search strategies.
By cycling between searching for images on the Internet with text queries, self-supervised training on downloaded images, determining which images were useful, and prioritizing what to search for next, Internet Explorer is able to achieve remarkable results; in just 30--40 hours of training on a single GPU desktop, it outperforms or matches the performance of CLIP oracle models and strong baselines that search the Internet in an undirected manner.

As we continue to explore the exciting possibilities of online representation learning on the open Web, several promising avenues for future work have emerged. Our work with Internet Explorer serves as the foundation for investigating more sophisticated metrics to better quantify the usefulness of a particular image, as well as alternative self-supervised learning algorithms that may offer a better fit for degenerate Internet images. The incorporation of Internet videos as a richer source of data, scaling to larger and more diverse datasets like ImageNet, and applying our approach to more challenging visual tasks, videos, and robotics, are just a few of the directions that can be explored. Furthermore, the possibility of fine-tuning vision-language models such as CLIP online using captions and search terms could lead to even more effective and adaptive models, further unlocking the potential of actively leveraging Internet for learning representations.

% What’s next on the open web?
% ● Scale to larger / more diverse datasets like ImageNet
% ● Apply to more challenging vision tasks, videos, and robotics
% ● Finetune a CLIP model online using captions + search terms!


%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "../thesis"
%%% End: